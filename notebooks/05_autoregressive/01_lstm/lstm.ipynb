{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b076bd1a-b236-4fbc-953d-8295b25122ae",
   "metadata": {},
   "source": [
    "# ðŸ¥™ LSTM on Recipe Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "658a95da-9645-4bcf-bd9d-4b95a4b6f582",
   "metadata": {},
   "source": [
    "In this notebook, we'll walk through the steps required to train your own LSTM on the recipes dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e0d56cc-4773-4029-97d8-26f882ba79c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-21 16:12:22.946312: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-21 16:12:23.081748: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-07-21 16:12:23.081769: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-07-21 16:12:23.099537: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-07-21 16:12:23.655843: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-07-21 16:12:23.655894: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-07-21 16:12:23.655900: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/clachris/Documents/projects/Generative_Deep_Learning_2nd_Edition/notebooks\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "import string\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, callbacks, losses\n",
    "\n",
    "%cd /home/clachris/Documents/projects/Generative_Deep_Learning_2nd_Edition/notebooks"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "339e6268-ebd7-4feb-86db-1fe7abccdbe5",
   "metadata": {},
   "source": [
    "## 0. Parameters <a name=\"parameters\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d8352af-343e-4c2e-8c91-95f8bac1c8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 10000\n",
    "MAX_LEN = 200\n",
    "EMBEDDING_DIM = 100\n",
    "N_UNITS = 128\n",
    "VALIDATION_SPLIT = 0.2\n",
    "SEED = 42\n",
    "LOAD_MODEL = False\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 25"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b7716fac-0010-49b0-b98e-53be2259edde",
   "metadata": {},
   "source": [
    "## 1. Load the data <a name=\"load\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93cf6b0f-9667-4146-8911-763a8a2925d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the full dataset\n",
    "with open('/home/clachris/Documents/projects/Generative_Deep_Learning_2nd_Edition/data/full_format_recipes.json') as json_data:\n",
    "    recipe_data = json.load(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23a74eca-f1b7-4a46-9a1f-b5806a4ed361",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Filter the dataset\n",
    "filtered_data = [\n",
    "    \"Recipe for \" + x[\"title\"] + \" | \" + \" \".join(x[\"directions\"])\n",
    "    for x in recipe_data\n",
    "    if \"title\" in x\n",
    "    and x[\"title\"] is not None\n",
    "    and \"directions\" in x\n",
    "    and x[\"directions\"] is not None\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "389c20de-0422-4c48-a7b4-6ee12a7bf0e2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20111 recipes loaded\n"
     ]
    }
   ],
   "source": [
    "# Count the recipes\n",
    "n_recipes = len(filtered_data)\n",
    "print(f\"{n_recipes} recipes loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b2e3cf7-e416-460e-874a-0dd9637bca36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recipe for Ham Persillade with Mustard Potato Salad and Mashed Peas  | Chop enough parsley leaves to measure 1 tablespoon; reserve. Chop remaining leaves and stems and simmer with broth and garlic in a small saucepan, covered, 5 minutes. Meanwhile, sprinkle gelatin over water in a medium bowl and let soften 1 minute. Strain broth through a fine-mesh sieve into bowl with gelatin and stir to dissolve. Season with salt and pepper. Set bowl in an ice bath and cool to room temperature, stirring. Toss ham with reserved parsley and divide among jars. Pour gelatin on top and chill until set, at least 1 hour. Whisk together mayonnaise, mustard, vinegar, 1/4 teaspoon salt, and 1/4 teaspoon pepper in a large bowl. Stir in celery, cornichons, and potatoes. Pulse peas with marjoram, oil, 1/2 teaspoon pepper, and 1/4 teaspoon salt in a food processor to a coarse mash. Layer peas, then potato salad, over ham.\n"
     ]
    }
   ],
   "source": [
    "example = filtered_data[9]\n",
    "print(example)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3f871aaf-d873-41c7-8946-e4eef7ac17c1",
   "metadata": {},
   "source": [
    "## 2. Tokenise the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b2064fb-5dcc-4657-b470-0928d10e2ddc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Pad the punctuation, to treat them as separate 'words'\n",
    "def pad_punctuation(s):\n",
    "    s = re.sub(f\"([{string.punctuation}])\", r\" \\1 \", s)\n",
    "    s = re.sub(\" +\", \" \", s)\n",
    "    return s\n",
    "\n",
    "text_data = [pad_punctuation(x) for x in filtered_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b87d7c65-9a46-492a-a5c0-a043b0d252f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Recipe for Ham Persillade with Mustard Potato Salad and Mashed Peas | Chop enough parsley leaves to measure 1 tablespoon ; reserve . Chop remaining leaves and stems and simmer with broth and garlic in a small saucepan , covered , 5 minutes . Meanwhile , sprinkle gelatin over water in a medium bowl and let soften 1 minute . Strain broth through a fine - mesh sieve into bowl with gelatin and stir to dissolve . Season with salt and pepper . Set bowl in an ice bath and cool to room temperature , stirring . Toss ham with reserved parsley and divide among jars . Pour gelatin on top and chill until set , at least 1 hour . Whisk together mayonnaise , mustard , vinegar , 1 / 4 teaspoon salt , and 1 / 4 teaspoon pepper in a large bowl . Stir in celery , cornichons , and potatoes . Pulse peas with marjoram , oil , 1 / 2 teaspoon pepper , and 1 / 4 teaspoon salt in a food processor to a coarse mash . Layer peas , then potato salad , over ham . '"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display an example of a recipe\n",
    "example_data = text_data[9]\n",
    "example_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9834f916-b21a-4104-acc9-f28d3bd7a8c1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-21 16:12:28.282938: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-21 16:12:28.283154: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-07-21 16:12:28.283184: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2023-07-21 16:12:28.283212: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2023-07-21 16:12:28.283237: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2023-07-21 16:12:28.283265: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2023-07-21 16:12:28.283291: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2023-07-21 16:12:28.283317: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2023-07-21 16:12:28.283343: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-07-21 16:12:28.283348: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-07-21 16:12:28.283811: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Convert to a Tensorflow Dataset\n",
    "text_ds = (\n",
    "    tf.data.Dataset.from_tensor_slices(text_data)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .shuffle(1000)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "884c0bcb-0807-45a1-8f7e-a32f2c6fa4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a vectorisation layer\n",
    "vectorize_layer = layers.TextVectorization(\n",
    "    standardize=\"lower\",\n",
    "    max_tokens=VOCAB_SIZE,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=MAX_LEN + 1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4d6dd34a-d905-497b-926a-405380ebcf98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapt the layer to the training set\n",
    "vectorize_layer.adapt(text_ds)\n",
    "vocab = vectorize_layer.get_vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f6c1c7ce-3cf0-40d4-a3dc-ab7090f69f2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: \n",
      "1: [UNK]\n",
      "2: .\n",
      "3: ,\n",
      "4: and\n",
      "5: to\n",
      "6: in\n",
      "7: the\n",
      "8: with\n",
      "9: a\n"
     ]
    }
   ],
   "source": [
    "# Display some token:word mappings\n",
    "for i, word in enumerate(vocab[:10]):\n",
    "    print(f\"{i}: {word}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1cc30186-7ec6-4eb6-b29a-65df6714d321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  26   16  557    1    8  298  335  189    4 1054  494   27  332  228\n",
      "  235  262    5  594   11  133   22  311    2  332   45  262    4  671\n",
      "    4   70    8  171    4   81    6    9   65   80    3  121    3   59\n",
      "   12    2  299    3   88  650   20   39    6    9   29   21    4   67\n",
      "  529   11  164    2  320  171  102    9  374   13  643  306   25   21\n",
      "    8  650    4   42    5  931    2   63    8   24    4   33    2  114\n",
      "   21    6  178  181 1245    4   60    5  140  112    3   48    2  117\n",
      "  557    8  285  235    4  200  292  980    2  107  650   28   72    4\n",
      "  108   10  114    3   57  204   11  172    2   73  110  482    3  298\n",
      "    3  190    3   11   23   32  142   24    3    4   11   23   32  142\n",
      "   33    6    9   30   21    2   42    6  353    3 3224    3    4  150\n",
      "    2  437  494    8 1281    3   37    3   11   23   15  142   33    3\n",
      "    4   11   23   32  142   24    6    9  291  188    5    9  412  572\n",
      "    2  230  494    3   46  335  189    3   20  557    2    0    0    0\n",
      "    0    0    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "# Display the same example converted to ints\n",
    "example_tokenised = vectorize_layer(example_data)\n",
    "print(example_tokenised.numpy())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8c195efb-84c6-4be0-a989-a7542188ad35",
   "metadata": {},
   "source": [
    "## 3. Create the Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "740294a1-1a6b-4c89-92f2-036d7d1b788b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: [[  26   16  247 ...    0    0    0]\n",
      " [  26   16 4163 ...    0    0    0]\n",
      " [  26   16  479 ...   96   22   40]\n",
      " ...\n",
      " [  26   16  264 ...    3  891   99]\n",
      " [  26   16  420 ...    0    0    0]\n",
      " [  26   16  187 ...    0    0    0]]\n",
      "y: [[  16  247 1446 ...    0    0    0]\n",
      " [  16 4163  265 ...    0    0    0]\n",
      " [  16  479  109 ...   22   40    5]\n",
      " ...\n",
      " [  16  264  725 ...  891   99    7]\n",
      " [  16  420  272 ...    0    0    0]\n",
      " [  16  187 1336 ...    0    0    0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nSo, we see that the x and y are just shifted by one!\\n'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the training set of recipes and the same text shifted by one word\n",
    "def prepare_inputs(text):\n",
    "    text = tf.expand_dims(text, -1)\n",
    "    tokenized_sentences = vectorize_layer(text)\n",
    "    x = tokenized_sentences[:, :-1]\n",
    "    y = tokenized_sentences[:, 1:]\n",
    "    return x, y\n",
    "\n",
    "train_ds = text_ds.map(prepare_inputs)\n",
    "first_batch = next(iter(train_ds))\n",
    "print(f'x: {first_batch[0]}')\n",
    "print(f'y: {first_batch[1]}')\n",
    "\n",
    "'''\n",
    "So, we see that the x and y are just shifted by one!\n",
    "'''"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "aff50401-3abe-4c10-bba8-b35bc13ad7d5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 4. Build the LSTM <a name=\"build\"></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "05ee60f7",
   "metadata": {},
   "source": [
    "## Mathematical Overview of the Recurrent Neural Netowkrs\n",
    "\n",
    "The *Recurrent Neural Network* (RNN) is one in which an output of the neural network is used as input again, hence the name *recurrent*. Values flow through the network, influencing later outputs. This architecture make sense for *sequential* tasks, takes that have a time or ordered structure. To predict the next word in a sentence, one needs to know what was said before. The translate, one must have gender and/or plurality of a noun that appears before the adjective, and so on. The RNN does this by passing an activation/output/hidden state to each iteration/pass-through that the subsequent iteration (perhaps also with the input from the sequence at that timestep) to produce output for the next iteration (and perhaps a prediction). In this way, information from earlier iterations can be passed down the sequence and influence predictions.\n",
    "\n",
    "In the vanilla RNN, given a data instance $\\bf{x}$ of length $T$, each iteration performs the following operations on the $t^{th}$ element of $\\bf{x}$:\n",
    "\n",
    "$$a^{<t>}=g_1(W_{aa}a^{<t-1>}+W_{ax}{\\bf{x}}^{<t>}+b_a)$$\n",
    "\n",
    "$$y^{<t>}=g_2(W_{ya}a^{<t>}+b_y)$$\n",
    "\n",
    "In the above, $W_{aa}$ are the weights associate with the activation of the previous iteration, $W_{ax}$ are the weights associated with the input from the sequence, $W_{ya}$ are the weights used to calculate the prediction, and $b_a$ and $b_y$ are the biases used to calculate the activation and the prediction, respectively. The $g$ functions are the activation functions of the *cell*. Note that this is all happening within a single cell, though we often *unroll* it to show how each element passes through the cell, along with the previous iteration's output. Here are the two graphics demonstrating this:\n",
    "\n",
    "<div style='text-align: center;'>\n",
    "    <img src='/home/clachris/Documents/projects/Generative_Deep_Learning_2nd_Edition/notebooks/Graphics/RNN_Cell.png' alt='RNN_Cell' width='500'>\n",
    "</div>\n",
    "\n",
    "In the above graphic, the next step would be to feed $a^{<t>}$, along with $\\mathbf{x}_t$, into the cell again. This looks like:\n",
    "\n",
    "<div style='text-align: center;'>\n",
    "    <img src='/home/clachris/Documents/projects/Generative_Deep_Learning_2nd_Edition/notebooks/Graphics/RNN_Unfurled.png' alt='RNN_Unfurled' width='500'>\n",
    "</div>\n",
    "\n",
    "They can also be stacked to give a Deep RNN:\n",
    "\n",
    "<div style='text-align: center;'>\n",
    "    <img src='/home/clachris/Documents/projects/Generative_Deep_Learning_2nd_Edition/notebooks/Graphics/Deep_RNN.png' alt='Deep_RNN' width='300'>\n",
    "</div>\n",
    "\n",
    "\n",
    "When the timeseries can be read forward and backward, we can even have a *Bidirectional RNN*:\n",
    "\n",
    "<div style='text-align: center;'>\n",
    "    <img src='/home/clachris/Documents/projects/Generative_Deep_Learning_2nd_Edition/notebooks/Graphics/Birdirectional_RNN.png' alt='Bridirectional_RNN' width='300'>\n",
    "</div>\n",
    "\n",
    "There are further several variants for what kind of prediction we want. Are we predicting an entire sequence sequentially, as in text generation, or are perhaps only a single value at a time, such as predicting a stock movement after some days' behavior? This leads to the following variants: \n",
    "\n",
    "*One-to-One*:\n",
    "\n",
    "<div style='text-align: center;'>\n",
    "    <img src='/home/clachris/Documents/projects/Generative_Deep_Learning_2nd_Edition/notebooks/Graphics/One-to-One.png' alt='One-to-One' width='300'>\n",
    "</div>\n",
    "\n",
    "*One-to-Many*:\n",
    "\n",
    "<div style='text-align: center;'>\n",
    "    <img src='/home/clachris/Documents/projects/Generative_Deep_Learning_2nd_Edition/notebooks/Graphics/One-to-Many.png' alt='One-to-Many' width='300'>\n",
    "</div>\n",
    "\n",
    "*Many-to-One*:\n",
    "\n",
    "<div style='text-align: center;'>\n",
    "    <img src='/home/clachris/Documents/projects/Generative_Deep_Learning_2nd_Edition/notebooks/Graphics/Many-to-One.png' alt='Many-to-One' width='300'>\n",
    "</div>\n",
    "\n",
    "*Many-to-Many (length of $\\mathbf{x}$ is equal to length of $\\mathbf{y}$)*:\n",
    "<div style='text-align: center;'>\n",
    "    <img src='/home/clachris/Documents/projects/Generative_Deep_Learning_2nd_Edition/notebooks/Graphics/Many-to-Many_x_equal_y.png' alt='Many-to-Many_x_equal_y' width='300'>\n",
    "</div>\n",
    "\n",
    "*Many-to-Many ($\\mathbf{x}$ is not equal to length of $\\mathbf{y}$)*:\n",
    "\n",
    "<div style='text-align: center;'>\n",
    "    <img src='/home/clachris/Documents/projects/Generative_Deep_Learning_2nd_Edition/notebooks/Graphics/Many-to-Many_x_nequal_y.png' alt='Many-to-Many_x_equal_y' width='300'>\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e008da94",
   "metadata": {},
   "source": [
    "## Mathematical Overview of the Long-Short Term Memory Network\n",
    "\n",
    "The above formulation suffers from several defects, most notably a *vanishing gradient*. As the sequence length increases, it becomes harder for the network to keep track of what is happening and the gradient plummets, taking the learning with it. To fix this, two novel approaches are the *Gated Reccurent Neural Network* (GRU) and the *Long-Short Term Neural Network* (LSTM).\n",
    "\n",
    "The GRU introduces the *Relevance* and *Update* gates. We will denote these gates by $\\Gamma_r$ and $\\Gamma_u$, respectively, where each gate is defined as:\n",
    "\n",
    "$$ \\Gamma = \\sigma (W\\mathbf{x}^{<t>} + Ua^{<t-1>}+b) $$\n",
    "\n",
    "In the above, $W,U$ and $b$ are the weights associated with the input, the weights associated with the activation, and the bias of the gate. $\\sigma$ is the sigmoid activation function. Thus, each gate has a value between 0 and 1.\n",
    "\n",
    "Then, the GRU will output an activation $a^{<t>}$ and $c^{<t>}$, which gives information about to handle the activation at the next timestep. In the GRU, these are calculated by:\n",
    "\n",
    "$$\\tilde{c}^{<t>} = tanh(W_c[\\Gamma_r \\odot a^{<t-1>}, {\\bf{x}}^{<t>}]+b_c)$$\n",
    "\n",
    "$$c^{<t>} = \\Gamma_u \\odot \\tilde{c}^{<t>} + (1-\\Gamma_u) c^{<t-1>}$$\n",
    "\n",
    "$$a^{<t>} = c^{<t>}$$\n",
    "\n",
    "Graphically, this looks like:\n",
    "\n",
    "<div style='text-align: center;'>\n",
    "    <img src='/home/clachris/Documents/projects/Generative_Deep_Learning_2nd_Edition/notebooks/Graphics/GRU.png' alt='GRU' width='300'>\n",
    "</div>\n",
    "\n",
    "The LSTM block introduces the *Forget* Gate $\\Gamma_f$ and the *Output* Gate $\\Gamma_o$. They are calculated in the following manner:\n",
    "\n",
    "$$\\tilde{c}^{<t>}=tanh(W_c[\\Gamma_r \\odot a^{<t-1>}, {\\bf{x}}^{<t>}]+b_c)$$\n",
    "\n",
    "$$c^{<t>}=\\Gamma_u \\odot \\tilde{c}^{<t>} + \\Gamma_f c^{<t-1>}$$\n",
    "\n",
    "$$a^{<t>}=\\Gamma_o \\odot c^{<t>}$$\n",
    "\n",
    "Graphically, this looks like:\n",
    "\n",
    "<div style='text-align: center;'>\n",
    "    <img src='/home/clachris/Documents/projects/Generative_Deep_Learning_2nd_Edition/notebooks/Graphics/LSTM.png' alt='LSTM' width='300'>\n",
    "</div>\n",
    "\n",
    "This cheatsheet from Stanford is quite helpful: https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-recurrent-neural-networks"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "57ea6905",
   "metadata": {},
   "source": [
    "## Overview of the Preprocessing and Embedding Layer\n",
    "\n",
    "Since we dealing with text sequences here, we need to talk a bit about how we deal with those. To begin, we need to *tokenize* the text. This essentially splits the text up into words and punctuation *tokens*. From there, we can remove capitalization, *stem* the words (turning things like *browsing*, *browsed* and *browsing* into just *brows*), and more. We could also break the text into just characters.\n",
    "\n",
    "Then, we need to count how many unique tokens we have, giving us our *Vocabulary* $V$. We might also prefer to replace sparsly occuring words with the *UNK*, or *unknown* token to reduce the number of parameters. \n",
    "\n",
    "Then, we create a vectorized layer which assigns a unique integer to each token based on frequency, with the integer $0$ reserved for padding, which is done so each data instance is the same length, the $1$ for the unknown words. Note that in this notebook, we have padded length of $201$, with the extra being the thing are going to predict.\n",
    "\n",
    "Now, at this point, one might be thinking we need to one-hot encode the integers, as we would use in normal multi-class classification. However, we would actually like to learn some *representation* of each word. So, we will use and *Embedding Layer*. We define the length of each embedding, in our case, $100$, giving us an embedding layer with $100 * 10000 = 1000000$ weights, which we can learn. \n",
    "\n",
    "Graphically, this looks like (with a length of only $4$):\n",
    "\n",
    "<div style='text-align: center;'>\n",
    "    <img src='/home/clachris/Documents/projects/Generative_Deep_Learning_2nd_Edition/notebooks/Graphics/EmbeddingLayer.png' alt='EmbeddingLayer' width='600'>\n",
    "</div>\n",
    "\n",
    "We note here something interesting. We can actually use this embedding on its own, as it represents the relationship between the various words to each other. Consider a $2D$ example comparing Royalty and Gender:\n",
    "\n",
    "<div style='text-align: center;'>\n",
    "    <img src='/home/clachris/Documents/projects/Generative_Deep_Learning_2nd_Edition/notebooks/Graphics/EmbeddingRelationships.png' alt='EmbeddingRelationships' width='500'>\n",
    "</div>\n",
    "\n",
    "So, we see that certain words are grouped together, as they should be, and that the distance from, say, *king* and *man* is about the same as *woman* and *queen*, signifying that the embeddings have captured some notion that the two groups of words are related. \n",
    "\n",
    "Now, at the end, the output of the model will be a probability vector $\\mathbf{p} \\in [0,1]^{|V|}, \\sum_{p \\in \\mathbf{p}} p = 1$, and we simply take the most likely words as our word choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9230b5bf-b4a8-48d5-b73b-6899a598f296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, None)]            0         \n",
      "                                                                 \n",
      " embedding_3 (Embedding)     (None, None, 100)         1000000   \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, None, 128)         117248    \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, None, 10000)       1290000   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,407,248\n",
      "Trainable params: 2,407,248\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = layers.Input(shape=(None,), dtype=\"int32\")\n",
    "x = layers.Embedding(VOCAB_SIZE, EMBEDDING_DIM)(inputs)\n",
    "x = layers.LSTM(N_UNITS, return_sequences=True)(x) # Note that the N_UNITS here is the size of the hidden output (a, in our mathematical formulation),\n",
    "# not the sequence length, which is 200. We are returning the sequences, which will be one hidden state for each token, and then feeding the hidden state\n",
    "# outputs to the dense layer, which will given a prediction for the next word for each hidden state\n",
    "outputs = layers.Dense(VOCAB_SIZE, activation=\"softmax\")(x) # The output will now be a probability vector over the entire vocabulary size for each\n",
    "# of the 200 outputs of the model\n",
    "lstm = models.Model(inputs, outputs)\n",
    "lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "800a3c6e-fb11-4792-b6bc-9a43a7c977ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if LOAD_MODEL:\n",
    "    # model.load_weights('./models/model')\n",
    "    lstm = models.load_model(\"./models/lstm\", compile=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "35b14665-4359-447b-be58-3fd58ba69084",
   "metadata": {},
   "source": [
    "## 5. Train the LSTM <a name=\"train\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ffb1bd3b-6fd9-4536-973e-6375bbcbf16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = losses.SparseCategoricalCrossentropy()\n",
    "lstm.compile(\"adam\", loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3ddcff5f-829d-4449-99d2-9a3cb68f7d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a TextGenerator checkpoint\n",
    "class TextGenerator(callbacks.Callback):\n",
    "    def __init__(self, index_to_word, top_k=10):\n",
    "        self.index_to_word = index_to_word \n",
    "        self.word_to_index = {\n",
    "            word: index for index, word in enumerate(index_to_word)\n",
    "        } # Reverses the vocab we created earlier to go from word to index\n",
    "\n",
    "    def sample_from(self, probs, temperature):  # Once we have our probability vectors, this will sample from them\n",
    "        probs = probs ** (1 / temperature) # This changes the probabilities by a temperature, closer to 0 is more deterministic and 1 is more random\n",
    "        probs = probs / np.sum(probs) # The probabilities no longer sum to one, so we normalize them\n",
    "        return np.random.choice(len(probs), p=probs), probs # Sampling a single value from the probabilities\n",
    "\n",
    "    def generate(self, start_prompt, max_tokens, temperature):\n",
    "        start_tokens = [\n",
    "            self.word_to_index.get(x, 1) for x in start_prompt.split()\n",
    "        ]  # <3>\n",
    "        sample_token = None\n",
    "        info = []\n",
    "        while len(start_tokens) < max_tokens and sample_token != 0:  # We start with some start prompt and are going to add to it until we reach the desired length\n",
    "            x = np.array([start_tokens]) # Has shape (batch_size=1, num_tokens)\n",
    "            y = self.model.predict(x, verbose=0) # Outputs shape (batch_size=1, len(x), 10000). Note, it is len(x) because it is predicting a staggered string,\n",
    "            # as in, it will skip the first word in the input, predict all the input, and then predict the next word\n",
    "            sample_token, probs = self.sample_from(y[0][-1], temperature)  # Samples from our y. Note y[0][-1] is because we remove the batch (of 1),\n",
    "            # then we take the last element to sample from, as we already have all the rest as the input prompt\n",
    "            info.append({\"prompt\": start_prompt, \"word_probs\": probs}) # Keeping track of what is happening\n",
    "            start_tokens.append(sample_token)  # Adding the chosen token to our input\n",
    "            start_prompt = start_prompt + \" \" + self.index_to_word[sample_token] # Adding the word to our start prompt, which will grow as we predict\n",
    "        print(f\"\\ngenerated text:\\n{start_prompt}\\n\")\n",
    "        return info\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        self.generate(\"recipe for\", max_tokens=100, temperature=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "349865fe-ffbe-450e-97be-043ae1740e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a model save checkpoint\n",
    "model_checkpoint_callback = callbacks.ModelCheckpoint(\n",
    "    filepath=\"./checkpoint/checkpoint.ckpt\",\n",
    "    save_weights_only=True,\n",
    "    save_freq=\"epoch\",\n",
    "    verbose=0,\n",
    ")\n",
    "\n",
    "tensorboard_callback = callbacks.TensorBoard(log_dir=\"./logs\")\n",
    "\n",
    "# Tokenize starting prompt\n",
    "text_generator = TextGenerator(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "461c2b3e-b5ae-4def-8bd9-e7bab8c63d8e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "629/629 [==============================] - ETA: 0s - loss: 2.2320\n",
      "generated text:\n",
      "recipe for breasts pudding with beef and potatoes with malt | melt butter in large saucepan over medium heat . continue simmer until just tender , about 30 minutes . divide rice mixture into bowl . toss toss evenly with remaining 3 / 4 cup oil . chopped remaining almonds atop each of potatoes and serve . \n",
      "\n",
      "629/629 [==============================] - 156s 247ms/step - loss: 2.2320\n",
      "Epoch 2/25\n",
      "629/629 [==============================] - ETA: 0s - loss: 2.0897\n",
      "generated text:\n",
      "recipe for lemon potato marinated | in a food processor combine the seed butter , the melted flavor more , using it , pressing it on outside ' logs of your holes . knead the dough through your fingers and starting for each . reduce potatoes with a time , leaving a paste , about 5 minutes in each plate . put the palms crosswise into a cavity , and cut into 1 / 4 - inch pieces . brush meat with a large pastry fine sheets , discarding strip the foil and drizzle with shell oil to loosen the\n",
      "\n",
      "629/629 [==============================] - 149s 237ms/step - loss: 2.0897\n",
      "Epoch 3/25\n",
      "629/629 [==============================] - ETA: 0s - loss: 1.9922\n",
      "generated text:\n",
      "recipe for apricot cake cake with mushroom layer and cream | on a plate sift together flour , baking powder , and salt . cook , switching position of ice water in a large pot over . stir with remaining 8 tablespoons butter ; toss to coat with remaining water . beat in the cream , . let box grater into your sink or a round bowl together with flour mixture on a work surface , then dip into it in a blender until smooth brown , 1 minute . add the tomato mixture , add 1 plums . top\n",
      "\n",
      "629/629 [==============================] - 153s 244ms/step - loss: 1.9922\n",
      "Epoch 4/25\n",
      "629/629 [==============================] - ETA: 0s - loss: 1.9207\n",
      "generated text:\n",
      "recipe for sweet squash with garlic , crimini , and dried vegetable anchovy butter | place parsley and heads and herbs in 6 large large roasting pan . sautÃ© lamb , skin side down , and other to 1 / 2 cup roasted carrots , with 1 / 4 cup water , and 2 teaspoons rice cloves . sautÃ© bacon 3 minutes . meanwhile , add minced lemon peel and cloves . in another medium bowl melt 1 cup milk 1 / 2 cup butter over medium - low heat until foam subsides and cook , stirring occasionally , stirring\n",
      "\n",
      "629/629 [==============================] - 154s 244ms/step - loss: 1.9207\n",
      "Epoch 5/25\n",
      "629/629 [==============================] - ETA: 0s - loss: 1.8653\n",
      "generated text:\n",
      "recipe for horseradish curry | in a grill bowl , cover the eggplant , heat the oil and in the spray fryer spread it with the spray . place the chorizo in the grill of the bread paste about 1 / 2 cup , dates , and 4 1 / 2 inches in drizzle in the oil , and bake for 20 minutes , discarding the desired . \n",
      "\n",
      "629/629 [==============================] - 152s 241ms/step - loss: 1.8653\n",
      "Epoch 6/25\n",
      "629/629 [==============================] - ETA: 0s - loss: 1.8204\n",
      "generated text:\n",
      "recipe for creamy candied sugar | preheat oven to oven . place crust beets in basket 2 pistachio pieces , then sprinkle with enough to coat with another setting . transfer to pan scatter cavity with mussels . add water , shallots , sugar , bay leaves , and salt and boil in caramelized beans until reduced to 1 cup , about 15 minutes . cool slightly . ( skin , if making sauce easier to remove it ; see fish easily . ) prepare barbecue ( medium - high heat ) . combine fennel , skin side down ,\n",
      "\n",
      "629/629 [==============================] - 153s 244ms/step - loss: 1.8204\n",
      "Epoch 7/25\n",
      "629/629 [==============================] - ETA: 0s - loss: 1.7835\n",
      "generated text:\n",
      "recipe for cheese and orange salad with sour butter roja topping | blend all sides in medium bowl until just combined . gradually stir in shiitake 1 / 3 cup cheese . spread 1 eggs at medium pastry ; drop 1 tablespoon vegetable oil into 4 - inch - diameter cookie mass . 3 . place garlic in heavy small skillet over medium heat . add onions and remaining 1 tablespoon oil to drippings in skillet and sautÃ© until crisp and fat forms , brushing down sides with glaze , about 1 minute per side . transfer clams to grill\n",
      "\n",
      "629/629 [==============================] - 153s 243ms/step - loss: 1.7835\n",
      "Epoch 8/25\n",
      "629/629 [==============================] - ETA: 0s - loss: 1.7520\n",
      "generated text:\n",
      "recipe for brazilian - eye grilled fish | make sure husks while but not have develop . \n",
      "\n",
      "629/629 [==============================] - 146s 232ms/step - loss: 1.7520\n",
      "Epoch 9/25\n",
      "629/629 [==============================] - ETA: 0s - loss: 1.7250\n",
      "generated text:\n",
      "recipe for broccolini and beef gumbo | attach deep - deep fryer ( fat ) or skillet over medium pot . holding fillets tightly open vents and let exposed rind and skin crosswise from lamb . rub bread crumbs all over vegetables in a large bowl with tongs , then transfer to a paste with a slow drippings . add onion and cabbage and sautÃ© 1 minute . reduce heat and simmer , uncovered , until tender , about 2 hours . 2 . heat 1 tablespoon oil in a 12 - inch heavy skillet over moderately high heat until\n",
      "\n",
      "629/629 [==============================] - 149s 237ms/step - loss: 1.7250\n",
      "Epoch 10/25\n",
      "629/629 [==============================] - ETA: 0s - loss: 1.7012\n",
      "generated text:\n",
      "recipe for apricot - citrus crostata | line and set over warm place over low heat . set aside . toast pecans over medium - high heat ( cover to other 1 tablespoon ) ; let cool . cut camp omelet into 8 flavoring from 3 pound squares ( if using ) , place bottom third of bread in a separate bowl . 3 . combine hot ice - milk if dry and use 1 1 / 2 cups wet on a work surface . gather dough all visible round intact , spacing evenly with flour . repeat with remaining\n",
      "\n",
      "629/629 [==============================] - 146s 232ms/step - loss: 1.7012\n",
      "Epoch 11/25\n",
      "629/629 [==============================] - ETA: 0s - loss: 1.6800\n",
      "generated text:\n",
      "recipe for baked eggplant with walla beans , chives , red pepper , palm , bacon and mushrooms | heat oil in heavy large nonstick skillet over medium - high heat . using slotted spoon , adding extra to 1 1 / 2 cups olive oil . add to potatoes , tossing to coat . bake until lamb is cooked through and cheese melts , about 25 minutes . transfer from bowl to cool to coat . transfer chicken to platter . mix salad in tomatoes . garnish all stew over . sprinkle with 1 / 3 cup cilantro .\n",
      "\n",
      "629/629 [==============================] - 149s 236ms/step - loss: 1.6800\n",
      "Epoch 12/25\n",
      "629/629 [==============================] - ETA: 0s - loss: 1.6611\n",
      "generated text:\n",
      "recipe for oysters rockefeller | heat oil in a casserole and microwave until the light golden and cooked through . set aside to thickness of the pickling leaves and cook until ham is just tender , 8â€“10 minutes more . reduce heat to low and cook until the meat is completely tender and a fast might pink , stirring is still soft slightly translucent . 5 . add a little water , mango - soy sauce , and a pinch of salt . transfer to a wire rack set basket on a plate and add the shredded beef and 2\n",
      "\n",
      "629/629 [==============================] - 152s 242ms/step - loss: 1.6611\n",
      "Epoch 13/25\n",
      "629/629 [==============================] - ETA: 0s - loss: 1.6438\n",
      "generated text:\n",
      "recipe for â€¢ beet and avocado risotto | heat oil in a dish in same manner , threading 1 1 / 4 cups sizzling and noodle and meat or cooked and mayonnaise butter . heat 1 tablespoon oil in a 7 - to 12 - inch heavy skillet over moderately high heat , stirring frequently , until light golden brown , about 5 minutes , 10 to 10 minutes total for medium - rare , 10 to 20 minutes total . transfer ragout to indirect baking pan and cool slightly to cover and serve burgers on sheet roast until golden\n",
      "\n",
      "629/629 [==============================] - 154s 245ms/step - loss: 1.6438\n",
      "Epoch 14/25\n",
      "629/629 [==============================] - ETA: 0s - loss: 1.6281\n",
      "generated text:\n",
      "recipe for scallops with garlic , spicy sauce and lemon and olive oil | line a 9 - inch square baking sheet with foil , leaving fat from them . jelly sauce and make each sandwiches with garlic , in a food processor and add enough of more water to cover the noodles for another medium for 6 inches , 1 to 3 2 minutes , or until well blended . grate the juice from oranges , allowing it on lightly oiled side to catch their fragrance . do not again briefly . heat a large heavy wok or iron\n",
      "\n",
      "629/629 [==============================] - 151s 240ms/step - loss: 1.6281\n",
      "Epoch 15/25\n",
      "629/629 [==============================] - ETA: 0s - loss: 1.6137\n",
      "generated text:\n",
      "recipe for arugula , apple , and blue cheese salad | combine lentils and 6 tablespoons black pepper in medium bowl ; pour 10 tablespoons olive oil over chicken . season with salt and pepper . on small baking sheet , mash zucchini and beets . divide chicken among 4 plates and arrange atop brussels sprout leaves . sprinkle with chili - basil sauce , leaving 1 / 4 - inch border from prosciutto , scraping up any bottom edge of grill pan . brush vegetables with olive oil and three wide 10 - inch patties . place chicken atop\n",
      "\n",
      "629/629 [==============================] - 153s 243ms/step - loss: 1.6137\n",
      "Epoch 16/25\n",
      "629/629 [==============================] - ETA: 0s - loss: 1.6004\n",
      "generated text:\n",
      "recipe for sesame tapenade | in a bowl cook bacon in a large bowl over moderate heat , stirring occasionally , until tender , 3 to 50 minutes . add flour and salt to taste . stir together just to coat the beans . reduce heat to medium and cook , stirring occasionally , until the potatoes are tender and start to curl , about 1 / 4 to 5 minutes . transfer to a plate and sprinkle with the salt . pour the wine mixture onto steaming sieve well - cooking . cover ice and cold water to make\n",
      "\n",
      "629/629 [==============================] - 153s 244ms/step - loss: 1.6004\n",
      "Epoch 17/25\n",
      "629/629 [==============================] - ETA: 0s - loss: 1.5880\n",
      "generated text:\n",
      "recipe for chicken with apples , red pepper , and beans | in a small saucepan bring all but all bits of the sauce ingredients over medium heat until evaporated but lightly flour . add 7 tablespoons butter and blend - semisweet water , whisking . stir in sugar , salt , and 3 tablespoons sugar . 2 . remove from the bowl and let sit at room temperature for about 15 minutes or . to make 24 cucumber - filled shell with ice cubes , spread the glaze and pudding in the wax paper ; top with the remaining\n",
      "\n",
      "629/629 [==============================] - 151s 240ms/step - loss: 1.5880\n",
      "Epoch 18/25\n",
      "629/629 [==============================] - ETA: 0s - loss: 1.5768\n",
      "generated text:\n",
      "recipe for pozole | combine all ingredients in a resealable plastic bag and seal and let stand at room temperature , stirring occasionally , about 20 minutes . \n",
      "\n",
      "629/629 [==============================] - 149s 237ms/step - loss: 1.5768\n",
      "Epoch 19/25\n",
      "629/629 [==============================] - ETA: 0s - loss: 1.5660\n",
      "generated text:\n",
      "recipe for blueberry tea cake | preheat oven to 300Â°f . butter a 13 - by 9 - by 9 large by 3 - inch ( 17 by 16 - by gas ) and roast in middle of oven 1 to 17 minutes . when edges are gray , reduce heat to low , then bake in 325Â°f , or 8 large 5 minutes for medium - rare . bake cake until just puffed and mixture forms , 30 to 25 minutes . cool completely on a rack 5 minutes . let cool , uncovered , 20 minutes before serving\n",
      "\n",
      "629/629 [==============================] - 152s 241ms/step - loss: 1.5660\n",
      "Epoch 20/25\n",
      "629/629 [==============================] - ETA: 0s - loss: 1.5562\n",
      "generated text:\n",
      "recipe for matzo balls in the oven , and zucchini on bottom or two | make the meat sizzles in a hot water and transfer the fish to a bowl . add the broth , orange juice , thai ginger , ginger , garlic , worcestershire , garlic , and sesame seeds . mix gently to combine liquid , about 1 tablespoon of lemon water before serving . taste - salsa verde . toss slightly . in a small saucepan stir the chicken with the dressing ; toss gently to combine . scatter about 1 tablespoon of the basil and\n",
      "\n",
      "629/629 [==============================] - 152s 241ms/step - loss: 1.5562\n",
      "Epoch 21/25\n",
      "629/629 [==============================] - ETA: 0s - loss: 1.5466\n",
      "generated text:\n",
      "recipe for potato , carrot , and apple potpie with lettuce cups sandwiches with ham , onions , swiss chard - scented ricotta , and braciole | preheat oven to 400Â°f . star anise , baking soda , and rosemary . cut watermelon crosswise into thin rounds . peel , reserving remainder ( such as flat - melon wedge , and 1 / 4 inch deep ) in half . place ribbons and squeezed cheesecloth into the 8 1 / 2 - inch julienne strips . in a bowl whisk together flour with a fork until fragrant , about 1\n",
      "\n",
      "629/629 [==============================] - 152s 241ms/step - loss: 1.5466\n",
      "Epoch 22/25\n",
      "629/629 [==============================] - ETA: 0s - loss: 1.5380\n",
      "generated text:\n",
      "recipe for coconut tart | flour a large bowl of a microplane boils standing down until shiny , fluffy , and whisk in the flour and chestnut to the process until the sugar . add the flour , then whisk the milk mixture , add the egg , and add the flour ; cook until the mixture curdles , about 2 to 2 minutes . add the egg yolk , flour , a metal spatula to coat , and chill it , covered , for 3 hours and according to the instructions the bars . ( thick ganache or spoon\n",
      "\n",
      "629/629 [==============================] - 150s 239ms/step - loss: 1.5380\n",
      "Epoch 23/25\n",
      "629/629 [==============================] - ETA: 0s - loss: 1.5294\n",
      "generated text:\n",
      "recipe for shrimp salad with lettuce and radish purÃ©e | coarsely slice garlic mixture , 3 . mash chicken with eggplants , cream , or peppers , chopped garlic and cinnamon and 1 / 4 teaspoon salt in a bowl and set about 1 tablespoon of 4 inches a chipotle - an 8 - to 3 - quart gratin dishes or with a 2 paper thickness across . seed tomato and chiles and oil with a large kettle , then add asparagus , onions , fennel bulb , celery , and chile . \n",
      "\n",
      "629/629 [==============================] - 150s 238ms/step - loss: 1.5294\n",
      "Epoch 24/25\n",
      "629/629 [==============================] - ETA: 0s - loss: 1.5215\n",
      "generated text:\n",
      "recipe for chilled avocado soup with lime basil salad and spicy chive cream | combine tangy basil and lemon peel in small bowl . process until sauce are slightly thickened , about 15 seconds . season with pepper and cilantro and serve . \n",
      "\n",
      "629/629 [==============================] - 148s 235ms/step - loss: 1.5215\n",
      "Epoch 25/25\n",
      "629/629 [==============================] - ETA: 0s - loss: 1.5143\n",
      "generated text:\n",
      "recipe for herb - steak kebabs with spicy salsa | finely grind garlic and sugar in processor . melt butter in skillet over medium heat . add tomatoes to parsnips and toss . cook bacon in skillet over medium heat until bright green , about 1 minute . drain . mix cherries with cumin and onion ; cook 3 garlic cloves , 1 minced garlic cloves , 1 / 4 teaspoon pepper , chopped rosemary and 1 / 2 teaspoon pepper in large pot until crisp - tender , about 7 minutes . add tomato , carrot , lemongrass ,\n",
      "\n",
      "629/629 [==============================] - 151s 240ms/step - loss: 1.5143\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f57f03120b0>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm.fit(\n",
    "    train_ds,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[model_checkpoint_callback, tensorboard_callback, text_generator],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "369bde44-2e39-4bc6-8549-a3a27ecce55c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_3_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/lstm/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/lstm/assets\n"
     ]
    }
   ],
   "source": [
    "# Save the final model\n",
    "lstm.save(\"./models/lstm\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d64e02d2-84dc-40c8-8446-40c09adf1e20",
   "metadata": {},
   "source": [
    "## 6. Generate text using the LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4ad23adb-3ec9-4e9a-9a59-b9f9bafca649",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_probs(info, vocab, top_k=5):\n",
    "    for i in info:\n",
    "        print(f\"\\nPROMPT: {i['prompt']}\")\n",
    "        word_probs = i[\"word_probs\"]\n",
    "        p_sorted = np.sort(word_probs)[::-1][:top_k]\n",
    "        i_sorted = np.argsort(word_probs)[::-1][:top_k]\n",
    "        for p, i in zip(p_sorted, i_sorted):\n",
    "            print(f\"{vocab[i]}:   \\t{np.round(100*p,2)}%\")\n",
    "        print(\"--------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3cf25578-d47c-4b26-8252-fcdf2316a4ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "generated text:\n",
      "recipe for roasted vegetables | chop 1 / 2 cup plus 2 tablespoons blueberries ; 1 / 3 cup cornstarch\n",
      "\n"
     ]
    }
   ],
   "source": [
    "info = text_generator.generate(\n",
    "    \"recipe for roasted vegetables | chop 1 /\", max_tokens=20, temperature=1.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9df72866-b483-4489-8e26-d5e1466410fa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PROMPT: recipe for roasted vegetables | chop 1 /\n",
      "4:   \t50.1%\n",
      "2:   \t36.57%\n",
      "3:   \t8.29%\n",
      "8:   \t3.49%\n",
      "6:   \t0.27%\n",
      "--------\n",
      "\n",
      "\n",
      "PROMPT: recipe for roasted vegetables | chop 1 / 2\n",
      "cup:   \t28.52%\n",
      "tsp:   \t23.96%\n",
      "teaspoon:   \t22.14%\n",
      "tablespoon:   \t4.4%\n",
      "inch:   \t2.95%\n",
      "--------\n",
      "\n",
      "\n",
      "PROMPT: recipe for roasted vegetables | chop 1 / 2 cup\n",
      "of:   \t18.6%\n",
      "hot:   \t6.87%\n",
      "warm:   \t6.2%\n",
      "granny:   \t2.91%\n",
      "corn:   \t2.83%\n",
      "--------\n",
      "\n",
      "\n",
      "PROMPT: recipe for roasted vegetables | chop 1 / 2 cup plus\n",
      "2:   \t47.75%\n",
      "1:   \t27.92%\n",
      "3:   \t1.91%\n",
      "a:   \t1.91%\n",
      "garlic:   \t1.83%\n",
      "--------\n",
      "\n",
      "\n",
      "PROMPT: recipe for roasted vegetables | chop 1 / 2 cup plus 2\n",
      "tablespoons:   \t46.41%\n",
      "tbsp:   \t16.42%\n",
      "teaspoons:   \t13.22%\n",
      "tsp:   \t7.55%\n",
      "cups:   \t2.14%\n",
      "--------\n",
      "\n",
      "\n",
      "PROMPT: recipe for roasted vegetables | chop 1 / 2 cup plus 2 tablespoons\n",
      "of:   \t9.1%\n",
      "lemon:   \t7.59%\n",
      "lime:   \t7.51%\n",
      "oil:   \t3.8%\n",
      "flour:   \t2.81%\n",
      "--------\n",
      "\n",
      "\n",
      "PROMPT: recipe for roasted vegetables | chop 1 / 2 cup plus 2 tablespoons blueberries\n",
      "in:   \t46.42%\n",
      "into:   \t31.57%\n",
      "and:   \t4.26%\n",
      "with:   \t4.07%\n",
      ".:   \t3.32%\n",
      "--------\n",
      "\n",
      "\n",
      "PROMPT: recipe for roasted vegetables | chop 1 / 2 cup plus 2 tablespoons blueberries ;\n",
      "set:   \t10.68%\n",
      "add:   \t7.45%\n",
      "blend:   \t4.9%\n",
      "transfer:   \t4.15%\n",
      "reserve:   \t3.89%\n",
      "--------\n",
      "\n",
      "\n",
      "PROMPT: recipe for roasted vegetables | chop 1 / 2 cup plus 2 tablespoons blueberries ; 1\n",
      "/:   \t62.08%\n",
      "teaspoon:   \t9.29%\n",
      ".:   \t6.11%\n",
      "tablespoon:   \t4.3%\n",
      "cup:   \t3.19%\n",
      "--------\n",
      "\n",
      "\n",
      "PROMPT: recipe for roasted vegetables | chop 1 / 2 cup plus 2 tablespoons blueberries ; 1 /\n",
      "2:   \t46.88%\n",
      "4:   \t36.01%\n",
      "3:   \t7.33%\n",
      "8:   \t6.76%\n",
      "a:   \t0.55%\n",
      "--------\n",
      "\n",
      "\n",
      "PROMPT: recipe for roasted vegetables | chop 1 / 2 cup plus 2 tablespoons blueberries ; 1 / 3\n",
      "cup:   \t51.02%\n",
      "/:   \t11.14%\n",
      "-:   \t9.74%\n",
      "tsp:   \t7.7%\n",
      "teaspoon:   \t6.65%\n",
      "--------\n",
      "\n",
      "\n",
      "PROMPT: recipe for roasted vegetables | chop 1 / 2 cup plus 2 tablespoons blueberries ; 1 / 3 cup\n",
      "of:   \t12.12%\n",
      "warm:   \t11.94%\n",
      "plus:   \t5.68%\n",
      "water:   \t5.3%\n",
      "hot:   \t5.0%\n",
      "--------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_probs(info, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "562e1fe8-cbcb-438f-9637-2f2a6279c924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "generated text:\n",
      "recipe for roasted vegetables | chop 1 / 2 tsp . salt and 1 / 4 tsp . pepper in\n",
      "\n"
     ]
    }
   ],
   "source": [
    "info = text_generator.generate(\n",
    "    \"recipe for roasted vegetables | chop 1 /\", max_tokens=20, temperature=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "56356f21-04ac-40e5-94ff-291eca6a7054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PROMPT: recipe for roasted vegetables | chop 1 /\n",
      "4:   \t82.83%\n",
      "2:   \t17.16%\n",
      "3:   \t0.01%\n",
      "8:   \t0.0%\n",
      "6:   \t0.0%\n",
      "--------\n",
      "\n",
      "\n",
      "PROMPT: recipe for roasted vegetables | chop 1 / 2\n",
      "cup:   \t58.81%\n",
      "tsp:   \t24.59%\n",
      "teaspoon:   \t16.59%\n",
      "tablespoon:   \t0.01%\n",
      "inch:   \t0.0%\n",
      "--------\n",
      "\n",
      "\n",
      "PROMPT: recipe for roasted vegetables | chop 1 / 2 tsp\n",
      ".:   \t100.0%\n",
      "salt:   \t0.0%\n",
      "each:   \t0.0%\n",
      ";:   \t0.0%\n",
      "butter:   \t0.0%\n",
      "--------\n",
      "\n",
      "\n",
      "PROMPT: recipe for roasted vegetables | chop 1 / 2 tsp .\n",
      "salt:   \t100.0%\n",
      "oil:   \t0.0%\n",
      "kosher:   \t0.0%\n",
      "butter:   \t0.0%\n",
      "pepper:   \t0.0%\n",
      "--------\n",
      "\n",
      "\n",
      "PROMPT: recipe for roasted vegetables | chop 1 / 2 tsp . salt\n",
      "and:   \t96.03%\n",
      ",:   \t3.84%\n",
      ".:   \t0.12%\n",
      "to:   \t0.01%\n",
      "in:   \t0.0%\n",
      "--------\n",
      "\n",
      "\n",
      "PROMPT: recipe for roasted vegetables | chop 1 / 2 tsp . salt and\n",
      "1:   \t99.99%\n",
      "pepper:   \t0.01%\n",
      "peel:   \t0.0%\n",
      "2:   \t0.0%\n",
      "core:   \t0.0%\n",
      "--------\n",
      "\n",
      "\n",
      "PROMPT: recipe for roasted vegetables | chop 1 / 2 tsp . salt and 1\n",
      "/:   \t99.97%\n",
      "tsp:   \t0.01%\n",
      ".:   \t0.01%\n",
      "teaspoon:   \t0.0%\n",
      "1:   \t0.0%\n",
      "--------\n",
      "\n",
      "\n",
      "PROMPT: recipe for roasted vegetables | chop 1 / 2 tsp . salt and 1 /\n",
      "2:   \t62.1%\n",
      "4:   \t37.9%\n",
      "3:   \t0.0%\n",
      "8:   \t0.0%\n",
      "1:   \t0.0%\n",
      "--------\n",
      "\n",
      "\n",
      "PROMPT: recipe for roasted vegetables | chop 1 / 2 tsp . salt and 1 / 4\n",
      "tsp:   \t99.97%\n",
      "teaspoon:   \t0.02%\n",
      "cup:   \t0.01%\n",
      "inch:   \t0.0%\n",
      "-:   \t0.0%\n",
      "--------\n",
      "\n",
      "\n",
      "PROMPT: recipe for roasted vegetables | chop 1 / 2 tsp . salt and 1 / 4 tsp\n",
      ".:   \t100.0%\n",
      "salt:   \t0.0%\n",
      "each:   \t0.0%\n",
      ";:   \t0.0%\n",
      "pepper:   \t0.0%\n",
      "--------\n",
      "\n",
      "\n",
      "PROMPT: recipe for roasted vegetables | chop 1 / 2 tsp . salt and 1 / 4 tsp .\n",
      "pepper:   \t99.88%\n",
      "salt:   \t0.12%\n",
      "butter:   \t0.0%\n",
      "oil:   \t0.0%\n",
      "water:   \t0.0%\n",
      "--------\n",
      "\n",
      "\n",
      "PROMPT: recipe for roasted vegetables | chop 1 / 2 tsp . salt and 1 / 4 tsp . pepper\n",
      "in:   \t99.92%\n",
      ".:   \t0.07%\n",
      "and:   \t0.01%\n",
      "to:   \t0.0%\n",
      ",:   \t0.0%\n",
      "--------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_probs(info, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2e434497-07f3-4989-a68d-3e31cf8fa4fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "generated text:\n",
      "recipe for chocolate ice cream | beat butter and sweetened together nuts in a food processor ( reserve remainder if\n",
      "\n",
      "\n",
      "PROMPT: recipe for chocolate ice cream |\n",
      "preheat:   \t18.56%\n",
      "in:   \t16.04%\n",
      "stir:   \t8.93%\n",
      "whisk:   \t8.54%\n",
      "bring:   \t6.9%\n",
      "--------\n",
      "\n",
      "\n",
      "PROMPT: recipe for chocolate ice cream | beat\n",
      "cream:   \t28.59%\n",
      "egg:   \t11.67%\n",
      "together:   \t8.11%\n",
      "eggs:   \t7.87%\n",
      "1:   \t4.96%\n",
      "--------\n",
      "\n",
      "\n",
      "PROMPT: recipe for chocolate ice cream | beat butter\n",
      "and:   \t58.76%\n",
      ",:   \t20.2%\n",
      "in:   \t9.05%\n",
      "with:   \t6.94%\n",
      "together:   \t0.91%\n",
      "--------\n",
      "\n",
      "\n",
      "PROMPT: recipe for chocolate ice cream | beat butter and\n",
      "sugar:   \t40.48%\n",
      "1:   \t10.66%\n",
      "butter:   \t5.42%\n",
      "2:   \t3.28%\n",
      "salt:   \t2.8%\n",
      "--------\n",
      "\n",
      "\n",
      "PROMPT: recipe for chocolate ice cream | beat butter and sweetened\n",
      "condensed:   \t26.57%\n",
      "sugar:   \t10.54%\n",
      "powdered:   \t3.29%\n",
      "egg:   \t3.07%\n",
      "in:   \t2.28%\n",
      "--------\n",
      "\n",
      "\n",
      "PROMPT: recipe for chocolate ice cream | beat butter and sweetened together\n",
      "in:   \t33.79%\n",
      "sugar:   \t8.92%\n",
      "butter:   \t3.93%\n",
      "remaining:   \t3.41%\n",
      "lemon:   \t3.12%\n",
      "--------\n",
      "\n",
      "\n",
      "PROMPT: recipe for chocolate ice cream | beat butter and sweetened together nuts\n",
      "in:   \t90.25%\n",
      "with:   \t2.72%\n",
      "and:   \t2.22%\n",
      "on:   \t1.26%\n",
      "into:   \t1.07%\n",
      "--------\n",
      "\n",
      "\n",
      "PROMPT: recipe for chocolate ice cream | beat butter and sweetened together nuts in\n",
      "a:   \t84.0%\n",
      "another:   \t3.64%\n",
      "large:   \t2.26%\n",
      "an:   \t2.23%\n",
      "medium:   \t1.45%\n",
      "--------\n",
      "\n",
      "\n",
      "PROMPT: recipe for chocolate ice cream | beat butter and sweetened together nuts in a\n",
      "food:   \t41.37%\n",
      "large:   \t16.82%\n",
      "bowl:   \t9.9%\n",
      "small:   \t7.37%\n",
      "blender:   \t6.32%\n",
      "--------\n",
      "\n",
      "\n",
      "PROMPT: recipe for chocolate ice cream | beat butter and sweetened together nuts in a food\n",
      "processor:   \t99.68%\n",
      "coloring:   \t0.15%\n",
      "food:   \t0.06%\n",
      "storage:   \t0.03%\n",
      "mill:   \t0.02%\n",
      "--------\n",
      "\n",
      "\n",
      "PROMPT: recipe for chocolate ice cream | beat butter and sweetened together nuts in a food processor\n",
      "until:   \t84.77%\n",
      "just:   \t3.3%\n",
      ".:   \t2.12%\n",
      "or:   \t1.49%\n",
      "with:   \t1.48%\n",
      "--------\n",
      "\n",
      "\n",
      "PROMPT: recipe for chocolate ice cream | beat butter and sweetened together nuts in a food processor (\n",
      "or:   \t24.2%\n",
      "mixture:   \t8.16%\n",
      "reserve:   \t7.48%\n",
      "with:   \t5.88%\n",
      "do:   \t4.58%\n",
      "--------\n",
      "\n",
      "\n",
      "PROMPT: recipe for chocolate ice cream | beat butter and sweetened together nuts in a food processor ( reserve\n",
      "remainder:   \t41.85%\n",
      "remaining:   \t25.92%\n",
      "any:   \t5.5%\n",
      "for:   \t4.67%\n",
      "1:   \t3.04%\n",
      "--------\n",
      "\n",
      "\n",
      "PROMPT: recipe for chocolate ice cream | beat butter and sweetened together nuts in a food processor ( reserve remainder\n",
      "for:   \t91.66%\n",
      "):   \t3.9%\n",
      "if:   \t2.01%\n",
      "in:   \t0.37%\n",
      "of:   \t0.29%\n",
      "--------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "info = text_generator.generate(\n",
    "    \"recipe for chocolate ice cream |\", max_tokens=20, temperature=1.0\n",
    ")\n",
    "print_probs(info, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "011cd0e0-956c-4a63-8ec3-f7dfed31764e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "generated text:\n",
      "recipe for chocolate ice cream | preheat oven to 350Â°f . line a baking sheet with parchment paper . in\n",
      "\n",
      "\n",
      "PROMPT: recipe for chocolate ice cream |\n",
      "preheat:   \t65.03%\n",
      "in:   \t31.43%\n",
      "stir:   \t1.68%\n",
      "whisk:   \t1.34%\n",
      "bring:   \t0.46%\n",
      "--------\n",
      "\n",
      "\n",
      "PROMPT: recipe for chocolate ice cream | preheat\n",
      "oven:   \t99.92%\n",
      "the:   \t0.08%\n",
      "a:   \t0.0%\n",
      "to:   \t0.0%\n",
      "broiler:   \t0.0%\n",
      "--------\n",
      "\n",
      "\n",
      "PROMPT: recipe for chocolate ice cream | preheat oven\n",
      "to:   \t100.0%\n",
      "temperature:   \t0.0%\n",
      "and:   \t0.0%\n",
      ".:   \t0.0%\n",
      "rack:   \t0.0%\n",
      "--------\n",
      "\n",
      "\n",
      "PROMPT: recipe for chocolate ice cream | preheat oven to\n",
      "350Â°f:   \t99.77%\n",
      "375Â°f:   \t0.2%\n",
      "400Â°f:   \t0.01%\n",
      "325Â°f:   \t0.01%\n",
      "425Â°f:   \t0.0%\n",
      "--------\n",
      "\n",
      "\n",
      "PROMPT: recipe for chocolate ice cream | preheat oven to 350Â°f\n",
      ".:   \t100.0%\n",
      "with:   \t0.0%\n",
      "and:   \t0.0%\n",
      "(:   \t0.0%\n",
      ",:   \t0.0%\n",
      "--------\n",
      "\n",
      "\n",
      "PROMPT: recipe for chocolate ice cream | preheat oven to 350Â°f .\n",
      "line:   \t54.82%\n",
      "butter:   \t42.75%\n",
      "in:   \t2.16%\n",
      "combine:   \t0.18%\n",
      "lightly:   \t0.03%\n",
      "--------\n",
      "\n",
      "\n",
      "PROMPT: recipe for chocolate ice cream | preheat oven to 350Â°f . line\n",
      "a:   \t56.86%\n",
      "bottom:   \t41.24%\n",
      "baking:   \t1.13%\n",
      "2:   \t0.6%\n",
      "large:   \t0.13%\n",
      "--------\n",
      "\n",
      "\n",
      "PROMPT: recipe for chocolate ice cream | preheat oven to 350Â°f . line a\n",
      "baking:   \t98.64%\n",
      "large:   \t0.84%\n",
      "9:   \t0.45%\n",
      "rimmed:   \t0.07%\n",
      "lightly:   \t0.0%\n",
      "--------\n",
      "\n",
      "\n",
      "PROMPT: recipe for chocolate ice cream | preheat oven to 350Â°f . line a baking\n",
      "sheet:   \t100.0%\n",
      "pan:   \t0.0%\n",
      "sheets:   \t0.0%\n",
      "dish:   \t0.0%\n",
      "pans:   \t0.0%\n",
      "--------\n",
      "\n",
      "\n",
      "PROMPT: recipe for chocolate ice cream | preheat oven to 350Â°f . line a baking sheet\n",
      "with:   \t100.0%\n",
      "or:   \t0.0%\n",
      ".:   \t0.0%\n",
      "pan:   \t0.0%\n",
      "and:   \t0.0%\n",
      "--------\n",
      "\n",
      "\n",
      "PROMPT: recipe for chocolate ice cream | preheat oven to 350Â°f . line a baking sheet with\n",
      "parchment:   \t95.32%\n",
      "foil:   \t4.68%\n",
      "wax:   \t0.0%\n",
      "paper:   \t0.0%\n",
      "plastic:   \t0.0%\n",
      "--------\n",
      "\n",
      "\n",
      "PROMPT: recipe for chocolate ice cream | preheat oven to 350Â°f . line a baking sheet with parchment\n",
      "paper:   \t100.0%\n",
      ".:   \t0.0%\n",
      "or:   \t0.0%\n",
      ",:   \t0.0%\n",
      "and:   \t0.0%\n",
      "--------\n",
      "\n",
      "\n",
      "PROMPT: recipe for chocolate ice cream | preheat oven to 350Â°f . line a baking sheet with parchment paper\n",
      ".:   \t100.0%\n",
      "and:   \t0.0%\n",
      ",:   \t0.0%\n",
      "or:   \t0.0%\n",
      ";:   \t0.0%\n",
      "--------\n",
      "\n",
      "\n",
      "PROMPT: recipe for chocolate ice cream | preheat oven to 350Â°f . line a baking sheet with parchment paper .\n",
      "in:   \t71.71%\n",
      "whisk:   \t15.9%\n",
      "sift:   \t6.05%\n",
      "combine:   \t2.38%\n",
      "butter:   \t1.83%\n",
      "--------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "info = text_generator.generate(\n",
    "    \"recipe for chocolate ice cream |\", max_tokens=20, temperature=0.2\n",
    ")\n",
    "print_probs(info, vocab)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
